<!doctype html><html lang=en>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=content-language content="en">
<meta name=color-scheme content="light dark">
<meta name=author content="Lyuwen Fu">
<meta name=description content="It supprises me that I am able to extract over hundred times efficiency gains in the SOTA LLM framework Megatron Core, but it happened. Here are the details.
Blended dataset index builder    The main logic of the existing implementation that builds the indices of the blended dataset starts from the calculation of the error of the expected sample size of the list of datasets in floating point number $f_{samples}[i] = wt[i] \times n_{tot}$ (calculated from the product of the dataset weight and the total expected sample size), with respect to the current number of samples allocated to the datasets $n_{curr}[i]$.">
<meta name=keywords content="blog,developer,personal">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="Finding efficiency gains in data loading procedure in Megatron Core framework">
<meta name=twitter:description content="It supprises me that I am able to extract over hundred times efficiency gains in the SOTA LLM framework Megatron Core, but it happened. Here are the details.
Blended dataset index builder    The main logic of the existing implementation that builds the indices of the blended dataset starts from the calculation of the error of the expected sample size of the list of datasets in floating point number $f_{samples}[i] = wt[i] \times n_{tot}$ (calculated from the product of the dataset weight and the total expected sample size), with respect to the current number of samples allocated to the datasets $n_{curr}[i]$.">
<meta property="og:title" content="Finding efficiency gains in data loading procedure in Megatron Core framework">
<meta property="og:description" content="It supprises me that I am able to extract over hundred times efficiency gains in the SOTA LLM framework Megatron Core, but it happened. Here are the details.
Blended dataset index builder    The main logic of the existing implementation that builds the indices of the blended dataset starts from the calculation of the error of the expected sample size of the list of datasets in floating point number $f_{samples}[i] = wt[i] \times n_{tot}$ (calculated from the product of the dataset weight and the total expected sample size), with respect to the current number of samples allocated to the datasets $n_{curr}[i]$.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://lyuwenfu.me/posts/megatron-core/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2024-08-20T00:00:00+00:00">
<meta property="article:modified_time" content="2024-08-20T00:00:00+00:00">
<title>
Finding efficiency gains in data loading procedure in Megatron Core framework · Lyuwen Fu
</title>
<link rel=canonical href=https://lyuwenfu.me/posts/megatron-core/>
<link rel=preload href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin>
<link rel=stylesheet href=/css/coder.min.d9fddbffe6f27e69985dc5fe0471cdb0e57fbf4775714bc3d847accb08f4a1f6.css integrity="sha256-2f3b/+byfmmYXcX+BHHNsOV/v0d1cUvD2Eesywj0ofY=" crossorigin=anonymous media=screen>
<link rel=stylesheet href=/css/coder-dark.min.002ee2378e14c7a68f1f0a53d9694ed252090987c4e768023fac694a4fc5f793.css integrity="sha256-AC7iN44Ux6aPHwpT2WlO0lIJCYfE52gCP6xpSk/F95M=" crossorigin=anonymous media=screen>
<link rel=icon type=image/png href=/images/lfu_logo_web@32.png sizes=32x32>
<link rel=icon type=image/png href=/images/lfu_logo_web@16.png sizes=16x16>
<link rel=apple-touch-icon href=/images/lfu_logo_web@144.png>
<link rel=apple-touch-icon sizes=180x180 href=/images/lfu_logo_web@144.png>
<meta name=generator content="Hugo 0.92.2">
</head>
<body class="preload-transitions colorscheme-auto">
<div class=float-container>
<a id=dark-mode-toggle class=colorscheme-toggle>
<i class="fa fa-adjust fa-fw" aria-hidden=true></i>
</a>
</div>
<main class=wrapper>
<nav class=navigation>
<section class=container>
<a class=navigation-title href=/>
Lyuwen Fu
</a>
<input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle>
<i class="fa fa-bars fa-fw" aria-hidden=true></i>
</label>
<ul class=navigation-list>
<li class=navigation-item>
<a class=navigation-link href=/posts/>Projects</a>
</li>
<li class=navigation-item>
<a class=navigation-link href=/about/>About</a>
</li>
</ul>
</section>
</nav>
<div class=content>
<section class="container post">
<article>
<header>
<div class=post-title>
<h1 class=title>
<a class=title-link href=https://lyuwenfu.me/posts/megatron-core/>
Finding efficiency gains in data loading procedure in Megatron Core framework
</a>
</h1>
</div>
<div class=post-meta>
<div class=date>
<span class=posted-on>
<i class="fa fa-calendar" aria-hidden=true></i>
<time datetime=2024-08-20T00:00:00Z>
August 20, 2024
</time>
</span>
<span class=reading-time>
<i class="fa fa-clock-o" aria-hidden=true></i>
2-minute read
</span>
</div>
<div class=authors>
<i class="fa fa-user" aria-hidden=true></i>
<a href=/authors/lyuwen-fu/>Lyuwen Fu</a></div>
<div class=tags>
<i class="fa fa-tag" aria-hidden=true></i>
<span class=tag>
<a href=/tags/large-language-models/>Large Language Models</a>
</span>
<span class=separator>•</span>
<span class=tag>
<a href=/tags/agi/>AGI</a>
</span>
<span class=separator>•</span>
<span class=tag>
<a href=/tags/neural-network/>Neural Network</a>
</span></div>
</div>
</header>
<div>
<p>It supprises me that I am able to extract over hundred times efficiency gains in the SOTA LLM framework Megatron Core, but it happened. Here are the details.</p>
<h4 id=blended-dataset-index-builder>
Blended dataset index builder
<a class=heading-link href=#blended-dataset-index-builder>
<i class="fa fa-link" aria-hidden=true></i>
</a>
</h4>
<p>The main logic of the existing implementation that builds the indices of the
blended dataset starts from the calculation of the error of the expected sample
size of the list of datasets in floating point number $f_{samples}[i] = wt[i] \times n_{tot}$
(calculated from the product of the dataset weight and the total expected
sample size), with respect to the current number of samples <em>allocated</em> to the
datasets $n_{curr}[i]$.
$$e_{samples}[i] = f_{samples}[i] - n_{curr}[i]$$
The dataset with the max error gets a increment to its allocation by 1.
Inherently, when the allocation of a dataset is larger than the expected sample size $f_{samples}[i]$,
it will never get any more allocations, since $e_{samples}[i] &lt; 0$.</p>
<p>Therefore, it&rsquo;s obvious we can simplify the algorithm, since before reaching the floor value of the the expected sample size $t_{samples}[i] = floor(f_{samples}[i])$,
the datasets will continue recieving allocations sooner or later, depending the total number of expected samples.
The situation only begins to change when all the datasets have reached the floor value of the expected sample size $n_{curr}[i] == t_{samples}[i]$.
Then based on the original algorithm, the datasets with the largest fractions $r_{samples}[i] = f_{samples}[i] - t_{samples}[i]$
(the remainder of the expected sample size in float modulo 1) will share the remaining allocations and fill the total number of samples $n_{tot}$.</p>
<p>Thus, the first step is to compute $t_{samples}[i]$ for all datasets, and get the current summary $\sum_{i} t_{samples}[i]$, and the remaining allocations
$n_{diff} = n_{tot} - \sum_{i} t_{samples}[i]$, then we increment the $n_{diff}$ datasets with the largest $r_{samples}[i]$, and get the final sample distribution
$n_{samples}[i]$. With the final sample distribution, we can build the indices for the blended dataset, and shuffle them to randomize the sampling procedure.</p>
<h5 id=references>
References:
<a class=heading-link href=#references>
<i class="fa fa-link" aria-hidden=true></i>
</a>
</h5>
<ul>
<li><a href=https://github.com/lyuwen/Megatron-LM/tree/optm_dataset>Lyuwen&rsquo;s Megatron Core code</a>.</li>
</ul>
</div>
<footer>
</footer>
</article>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:!0},{left:'$',right:'$',display:!1},{left:'\\(',right:'\\)',display:!1},{left:'\\[',right:'\\]',display:!0}]})"></script>
</section>
</div>
<footer class=footer>
<section class=container>
©
2021 -
2024
Lyuwen Fu
·
Powered by <a href=https://gohugo.io/>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/>Coder</a>.
</section>
</footer>
</main>
<script src=/js/coder.min.39a51230dce2ac866c049b52573e38bf60666af4bc63c1bdf203b9b2d95b1cd6.js integrity="sha256-OaUSMNzirIZsBJtSVz44v2BmavS8Y8G98gO5stlbHNY="></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7C7Y626LWM"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-7C7Y626LWM',{anonymize_ip:!1})}</script>
</body>
</html>