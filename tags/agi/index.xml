<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AGI on Lyuwen Fu</title><link>https://lyuwenfu.me/tags/agi/</link><description>Recent content in AGI on Lyuwen Fu</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 20 Aug 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://lyuwenfu.me/tags/agi/index.xml" rel="self" type="application/rss+xml"/><item><title>Finding efficiency gains in data loading procedure in Megatron Core framework</title><link>https://lyuwenfu.me/posts/megatron-core/</link><pubDate>Tue, 20 Aug 2024 00:00:00 +0000</pubDate><guid>https://lyuwenfu.me/posts/megatron-core/</guid><description>It supprises me that I am able to extract over hundred times efficiency gains in the SOTA LLM framework Megatron Core, but it happened. Here are the details.
Blended dataset index builder The main logic of the existing implementation that builds the indices of the blended dataset starts from the calculation of the error of the expected sample size of the list of datasets in floating point number $f_{samples}[i] = wt[i] \times n_{tot}$ (calculated from the product of the dataset weight and the total expected sample size), with respect to the current number of samples allocated to the datasets $n_{curr}[i]$.</description></item></channel></rss>